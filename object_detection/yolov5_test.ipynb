{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "anchor:\n",
    "\n",
    "anchors为 3x6的数组，每一行代表3个anchors的宽高\n",
    "\n",
    "在Detect阶段，对anchors view 为 3x3x2的tensor,并除以对应层的stride\n",
    "\n",
    "混合精度训练：\n",
    "\n",
    "在训练阶段，使用torch中的amp模块来进行智能混合精度训练，这一部分见[Automatic mixed precision training](https://pytorch.org/docs/stable/amp.html?highlight=amp#module-torch.cuda.amp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Yolov5中的loss部分\n",
    "- 类别和目标均采用二元交叉熵损失，并由各自的权重负责\n",
    "- 坐标使用CIoU损失\n",
    "\n",
    "初始化部分：\n",
    "\n",
    "balance为每个检测层的权重； p3 p5 p7\n",
    "\n",
    "stride 8 16 32\n",
    "\n",
    "build_targets:\n",
    "\n",
    "见代码部分\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeLoss:\n",
    "    # Compute losses\n",
    "    def __init__(self, model, autobalance=False):\n",
    "        super(ComputeLoss, self).__init__()\n",
    "        device = next(model.parameters()).device  # get model device\n",
    "        h = model.hyp  # hyperparameters\n",
    "\n",
    "        # Define criteria\n",
    "        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))\n",
    "        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))\n",
    "\n",
    "        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3\n",
    "        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets\n",
    "\n",
    "        # Focal loss\n",
    "        g = h['fl_gamma']  # focal loss gamma\n",
    "        if g > 0:\n",
    "            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)\n",
    "\n",
    "        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module\n",
    "        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7\n",
    "        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index\n",
    "        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, model.gr, h, autobalance\n",
    "        for k in 'na', 'nc', 'nl', 'anchors':\n",
    "            setattr(self, k, getattr(det, k))\n",
    "\n",
    "    def __call__(self, p, targets):  # predictions, targets, model\n",
    "        device = targets.device\n",
    "        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)\n",
    "        tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets\n",
    "\n",
    "        # Losses\n",
    "        for i, pi in enumerate(p):  # layer index, layer predictions\n",
    "            b, a, gj, gi = indices[i]  # image, anchor, grid y, grid x\n",
    "            tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj\n",
    "\n",
    "            n = b.shape[0]  # number of targets\n",
    "            if n:\n",
    "                # 取预测结果中在targets位置的值\n",
    "                ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets\n",
    "\n",
    "                # Regression\n",
    "                pxy = ps[:, :2].sigmoid() * 2. - 0.5  # sigmoid *2 -0.5 取值范围(-0.5,1.5) 表示预测的中心点偏移数值\n",
    "                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]  # (sigmoid *2)^2 * anchors 范围(0,4) * anchors 表示宽高\n",
    "                pbox = torch.cat((pxy, pwh), 1)  # predicted box\n",
    "                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)\n",
    "                lbox += (1.0 - iou).mean()  # iou loss\n",
    "\n",
    "                # Objectness\n",
    "                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * iou.detach().clamp(0).type(tobj.dtype)  # iou ratio\n",
    "\n",
    "                # Classification\n",
    "                if self.nc > 1:  # cls loss (only if multiple classes)\n",
    "                    t = torch.full_like(ps[:, 5:], self.cn, device=device)  # targets\n",
    "                    t[range(n), tcls[i]] = self.cp\n",
    "                    lcls += self.BCEcls(ps[:, 5:], t)  # BCE\n",
    "\n",
    "                # Append targets to text file\n",
    "                # with open('targets.txt', 'a') as file:\n",
    "                #     [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in torch.cat((txy[i], twh[i]), 1)]\n",
    "\n",
    "            obji = self.BCEobj(pi[..., 4], tobj)\n",
    "            lobj += obji * self.balance[i]  # obj loss\n",
    "            if self.autobalance:\n",
    "                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()\n",
    "\n",
    "        if self.autobalance:\n",
    "            self.balance = [x / self.balance[self.ssi] for x in self.balance]\n",
    "        lbox *= self.hyp['box']\n",
    "        lobj *= self.hyp['obj']\n",
    "        lcls *= self.hyp['cls']\n",
    "        bs = tobj.shape[0]  # batch size\n",
    "\n",
    "        loss = lbox + lobj + lcls\n",
    "        return loss * bs, torch.cat((lbox, lobj, lcls, loss)).detach()\n",
    "\n",
    "    def build_targets(self, p, targets):\n",
    "        \"\"\"\n",
    "        建立训练用的与标签匹配的anchors\n",
    "        Args:\n",
    "            p(list(tensor)):pred,多个层的输出，每个层的输出为(batch_size,num_anchors, h,w,nc)\n",
    "            targets(tensor): shape (num_labels, 6) where 6 contains (batch_id,class,xywh)\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Build targets for compute_loss(), input targets(image,class,x,y,w,h)\n",
    "        na, nt = self.na, targets.shape[0]  # number of anchors, targets\n",
    "        tcls, tbox, indices, anch = [], [], [], []\n",
    "        gain = torch.ones(7, device=targets.device)  # normalized to grid space gain\n",
    "        # 将anchors中的每个anchor索引(0,1,2)复制nt份，nt为targets的数量 得到shape (na,nt)\n",
    "        ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)  # same as .repeat_interleave(nt)\n",
    "        # 首先对targets重复(na,1,1)遍，得到shape (na,nt,6),然后将其与ai进行拼接，得到(na,nt, 7)，其中7为target,anchor_index\n",
    "        # 这样，即对targets复制成了na份，每个anchor在初始时都对应所有的targets\n",
    "        targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices\n",
    "\n",
    "        # anchor的偏差， 这里为5个位置的偏差， [0,0], [0.5,0],...\n",
    "        # 对之后的预测进行偏移，使得坐标预测范围为[-0.5,1.5]\n",
    "        g = 0.5  # bias\n",
    "        off = torch.tensor([[0, 0],\n",
    "                            [1, 0], [0, 1], [-1, 0], [0, -1],  # j,k,l,m\n",
    "                            # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm\n",
    "                            ], device=targets.device).float() * g  # offsets\n",
    "\n",
    "        for i in range(self.nl): # 对每一检测层\n",
    "            # anchors shape (nl, na, 2)\n",
    "            anchors = self.anchors[i]\n",
    "            gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xywh gain = 1 * feat_size\n",
    "\n",
    "            # Match targets to anchors\n",
    "            t = targets * gain #targets*对应层的坐标增益(feat_size)得到标签在对应层的实际坐标\n",
    "            if nt:\n",
    "                # Matches\n",
    "                # t[] (3,36,2) anchors[:,None] (3,1,2) => 3,36,2\n",
    "                r = t[:, :, 4:6] / anchors[:, None]  # wh ratio 计算target比上anchors的wh ratio,\n",
    "                # 计算w/w' h/h'中的长边/短边的比值，并取max(w ratio, h ratio)作为targets/anchors的比值，如果小于阈值，则说明匹配\n",
    "                j = torch.max(r, 1. / r).max(2)[0] < self.hyp['anchor_t']  # compare\n",
    "                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))\n",
    "                t = t[j]  # filter\n",
    "\n",
    "                # Offsets\n",
    "                gxy = t[:, 2:4]  # grid xy label的中心坐标\n",
    "                gxi = gain[[2, 3]] - gxy  # inverse # 反向后，当前点与对边的距离\n",
    "                # 这里判断中心点落在cell里面的哪个方向，并取该方向相邻的两个cell作为正样本anchor\n",
    "                j, k = ((gxy % 1. < g) & (gxy > 1.)).T # gt targets不在四个边上，且在中心点左边或上方\n",
    "                l, m = ((gxi % 1. < g) & (gxi > 1.)).T # gt targets不在四个边上，且在中心点右边或下方\n",
    "                j = torch.stack((torch.ones_like(j), j, k, l, m)) # shape (5,num_matched_gts) (1,中心点左边,上，右，下）\n",
    "                t = t.repeat((5, 1, 1))[j] # 对targets重复5次并选择最近的三个\n",
    "                # zeros 1,num_matched_gts,2 + off 5,1,2 = shape 5,num_xx,2  filter => filter,2\n",
    "                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j] # 中心点xy加上偏移，并保留最近的三个，\n",
    "            else:\n",
    "                t = targets[0]\n",
    "                offsets = 0\n",
    "\n",
    "            # Define\n",
    "            b, c = t[:, :2].long().T  # image, class\n",
    "            gxy = t[:, 2:4]  # grid xy\n",
    "            gwh = t[:, 4:6]  # grid wh\n",
    "            gij = (gxy - offsets).long() # 得到gt的i，j个cell坐标\n",
    "            gi, gj = gij.T  # grid xy indices\n",
    "\n",
    "            # Append\n",
    "            a = t[:, 6].long()  # anchor indices\n",
    "            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices\n",
    "            tbox.append(torch.cat((gxy - gij, gwh), 1))  # box\n",
    "            anch.append(anchors[a])  # anchors\n",
    "            tcls.append(c)  # class\n",
    "\n",
    "        return tcls, tbox, indices, anch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}