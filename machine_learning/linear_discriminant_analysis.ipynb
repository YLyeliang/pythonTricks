{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 线性判别分析(LDA)\n",
    "经典的线性学习方法。思想：将样例投影到直线上，使得同样例的投影点尽可能近，不同样例的投影点尽可能远。即“投影后类内方差最小，类间方差最大”。\n",
    "\n",
    "### 瑞利商（Rayleigh quotient）与广义瑞利商（genralized Rayleigh quotient）\n",
    "瑞利商是指这样的函数$R(A,x)$:\n",
    "\n",
    "$R(A,x) = \\frac{x^HAx}{x^Hx}$\n",
    "\n",
    "其中$x$为非零向量，而A为$n\\times n$的Hermitan矩阵。所谓的Hermitan矩阵就是满足共轭转置矩阵和自己相等的矩阵，即$A^H=A$。\n",
    "如果我们的矩阵A是实矩阵，则满足$A^T=A$的矩阵即为Hermitan矩阵。\n",
    "\n",
    "瑞利商R(A,x)有一个非常重要的性质，即它的最大值等于矩阵A最大的特征值，而最小值等于矩阵A的最小的特征值，也就是满足\n",
    "\n",
    "$\\lambda_{min} \\leq \\frac{x^HAx}{x^Hx} \\leq \\lambda_{max}$\n",
    "\n",
    "当向量x是标准正交基时，即满足$x^Hx=1$时，瑞利商退化为：$R(A,x)=x^HAx$，这个形式在谱聚类和PCA中都有出现。\n",
    "\n",
    "广义瑞利商是指这样的函数$R(A,B,x)$:\n",
    "\n",
    "$R(A,x) = \\frac{x^HAx}{x^HBx}$\n",
    "\n",
    "其中x为非零向量，而A,B为$n×n$的Hermitan矩阵。B为正定矩阵。它的最大值和最小值是什么呢？\n",
    "其实我们只要通过将其通过标准化就可以转化为瑞利商的格式。我们令$x=B^{-1/2}x'$,则分母转化为：\n",
    "\n",
    "$x^HBx = x'^H(B^{-1/2})^HBB^{-1/2}x' = x'^HB^{-1/2}BB^{-1/2}x' = x'^Hx'$\n",
    "\n",
    "分子则转化为：\n",
    "\n",
    "$x^HAx =  x'^HB^{-1/2}AB^{-1/2}x'$\n",
    "\n",
    "此时，公式转化为：\n",
    "\n",
    "$R(A,B,x') = \\frac{x'^HB^{-1/2}AB^{-1/2}x'}{x'^Hx'}$\n",
    "\n",
    "可以很快的知道，$R(A,B,x′)$的最大值为矩阵$B^{-1/2}AB^{-1/2}$的最大特征值，或者说矩阵$B^{-1/2}A$的最大特征值，而最小值为矩阵$B^{-1/2}A$的最小特征值。\n",
    "### 二类LDA原理\n",
    "假设数据集为$D=\\{(x_1,y_1), (x_2,y_2), ...,((x_m,y_m))\\}$，其中样本$x_i$为n维向量，$y_i \\in \\{0,1\\}$,定义$N_j(j=0,1)$为第j类样本的数，$X_j(j=0,1)$为第j类样本的集合，$\\mu_j(j=0,1)$为第j类样本的均值向量，$\\Sigma_j(j=0,1)$为第j类样本的协方差矩阵。\n",
    "\n",
    "$\\mu_j = \\frac{1}{N_j}\\sum\\limits_{x \\in X_j}x\\;\\;(j=0,1)$\n",
    "\n",
    "$\\Sigma_j = \\sum\\limits_{x \\in X_j}(x-\\mu_j)(x-\\mu_j)^T\\;\\;(j=0,1)$\n",
    "\n",
    "由于是两类数据，因此我们只需要将数据投影到一条直线上即可。假设我们的投影直线是向量$w$,则对任意一个样本本$x_i$,它在直线w的投影为$w^Tx_i$,对于我们的两个类别的中心点$μ_0,μ_1$,在在直线$w$的投影为$w^Tμ_0$和$w^Tμ_1$。由于LDA需要让不同类别的数据的类别中心之间的距离尽可能的大，也就是我们要最大化$||w^Tμ_0−w^Tμ_1||^2_2$,同时我们希望同一种类别数据的投影点尽可能的接近，也就是要同类样本投影点的协方差$w^TΣ_0w$和$w^TΣ_1w$尽可能的小，即最小化$w^TΣ_0w+w^TΣ_1w$。综上所述，我们的优化目标为：\n",
    "\n",
    "$\\underbrace{arg\\;max}_w\\;\\;J(w) = \\frac{||w^T\\mu_0-w^T\\mu_1||_2^2}{w^T\\Sigma_0w+w^T\\Sigma_1w} = \\frac{w^T(\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^Tw}{w^T(\\Sigma_0+\\Sigma_1)w}$\n",
    "\n",
    "一般，定义类内散度矩阵$S_w$为：\n",
    "\n",
    "$S_w = \\Sigma_0 + \\Sigma_1 = \\sum\\limits_{x \\in X_0}(x-\\mu_0)(x-\\mu_0)^T + \\sum\\limits_{x \\in X_1}(x-\\mu_1)(x-\\mu_1)^T$\n",
    "\n",
    "类间散度矩阵$S_b$:\n",
    "\n",
    "$S_b = (\\mu_0-\\mu_1)(\\mu_0-\\mu_1)^T$\n",
    "\n",
    "则，得到优化目标为:\n",
    "\n",
    "$\\underbrace{arg\\;max}_w\\;\\;J(w) = \\frac{w^TS_bw}{w^TS_ww}$\n",
    "\n",
    "这就是我们的广义瑞利商！利用广义瑞利商的性质，知道$J(w′)$最大值为矩阵$S^{−\\frac{1}{2}}_wS_bS^{−\\frac{1}{2}}_w$的最大特征值，而对应的$w′$为$S^{−\\frac{1}{2}}_wS_bS^{−\\frac{1}{2}}_w$的最大特征值对应的特征向量! 而$S^{−1}_wS_b$的特征值和$S^{−1/2}_wS_bS^{−1/2}_w$的特征值相同,$S^{−1}_wS_b$的特征向量$w$和$S^{−1/2}_wS_bS^{−1/2}_w$的特征向量$w′$满足$w=S^{−1/2}_ww′$的关系! \n",
    "\n",
    "注意到对于二类的时候，$S_bw$的方向恒平行于$μ_0−μ_1$,不妨令$S_bw=λ(μ_0−μ_1)$，将其带入：$(S^{−1}_wS_b)w=λw$，可以得到$w=S^{−1}_w(μ_0−μ_1)$， 也就是说我们只要求出原始二类样本的均值和方差就可以确定最佳的投影方向w了。\n",
    "\n",
    "\n",
    "现在我们对LDA降维的流程做一个总结。\n",
    "\n",
    "　　　　输入：数据集$D={(x1,y1),(x2,y2),...,((xm,ym))}$,其中任意样本xi为n维向量，$yi∈{C1,C2,...,Ck}$，降维到的维度d。\n",
    "\n",
    "　　　　输出：降维后的样本集$D′$\n",
    "\n",
    "　　　　1) 计算类内散度矩阵$S_w$\n",
    "\n",
    "　　　　2) 计算类间散度矩阵$S_b$\n",
    "\n",
    "　　　　3) 计算矩阵$S^{−1}_wS_b$\n",
    "\n",
    "　　　　4）计算$S^{−1}_wS_b$的最大的d个特征值和对应的d个特征向量$(w1,w2,...wd)$,得到投影矩阵$WW$\n",
    "\n",
    "　　　　5) 对样本集中的每一个样本特征xi,转化为新的样本$z_i=W^Tx_i$\n",
    "    \n",
    "　　　　6) 得到输出样本集$D′={(z1,y1),(z2,y2),...,((zm,ym))}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 导入相应的包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7123,  2.2205, -0.1303, ..., -0.2002, -0.8216, -0.6295],\n",
       "       [ 0.8823, -0.7046,  1.1753, ...,  1.3398,  0.5493,  1.4757],\n",
       "       [ 0.8459, -0.7302,  1.1753, ...,  1.0681,  0.1308,  1.6293],\n",
       "       ...,\n",
       "       [ 1.028 ,  2.2975, -0.5779, ..., -1.6949, -1.8607, -1.0443],\n",
       "       [-1.3038, -1.0809, -0.3168, ...,  0.1622,  0.7369,  0.4031],\n",
       "       [-0.4051,  1.2968,  0.0563, ...,  1.0681,  0.7369, -0.8968]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以红酒数据为例 红酒数据有3个类别，每个类别有13个特征\n",
    "# load data\n",
    "df_wine = pd.read_csv(\"wine/wine.data\",header=None)\n",
    "\n",
    "# train:data = 7:3\n",
    "x,y = df_wine.iloc[:,1:].values,df_wine.iloc[:,0].values\n",
    "x_train,x_test,y_train,y_test =  train_test_split(x,y,test_size=0.3,stratify=y, random_state=0)\n",
    "\n",
    "# 标准化单位方差\n",
    "sc = StandardScaler()\n",
    "x_train_std = sc.fit_transform(x_train)\n",
    "x_test_std = sc.fit_transform(x_test)\n",
    "x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.9066, -0.3497,  0.3201, -0.7189,  0.5056,  0.8807,  0.9589,\n",
       "        -0.5516,  0.5416,  0.2338,  0.5897,  0.6563,  1.2075]),\n",
       " array([-0.8749, -0.2848, -0.3735,  0.3157, -0.3848, -0.0433,  0.0635,\n",
       "        -0.0946,  0.0703, -0.8286,  0.3144,  0.3608, -0.7253]),\n",
       " array([ 0.1992,  0.866 ,  0.1682,  0.4148, -0.0451, -1.0286, -1.2876,\n",
       "         0.8287, -0.7795,  0.9649, -1.209 , -1.3622, -0.4013])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算均值向量\n",
    "np.set_printoptions(precision=4)\n",
    "mean_vecs=[]\n",
    "for label in range(1,4):\n",
    "    mean_vecs.append(np.mean(x_train_std[y_train==label],axis=0))\n",
    "mean_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2448,  0.0967, -0.1276, -0.1105, -0.0726,  0.2374,  0.0753,\n",
       "         0.0231,  0.1102,  0.4261,  0.1411, -0.0155,  0.1224],\n",
       "       [ 0.0967,  2.2666,  0.1168,  0.3517, -0.2622, -0.0467, -0.0186,\n",
       "         0.2194,  0.0187, -0.3939, -0.4167,  0.0787, -0.2492],\n",
       "       [-0.1276,  0.1168,  2.6024,  1.6442,  0.5364,  0.3947,  0.3191,\n",
       "         0.4553, -0.0353,  0.06  ,  0.167 ,  0.1987, -0.0081],\n",
       "       [-0.1105,  0.3517,  1.6442,  2.1604,  0.325 ,  0.1535,  0.1222,\n",
       "         0.273 , -0.0824, -0.068 ,  0.0336,  0.2548, -0.1201],\n",
       "       [-0.0726, -0.2622,  0.5364,  0.325 ,  2.4397,  0.2384,  0.1433,\n",
       "        -0.5166,  0.2566,  0.1445,  0.1777, -0.0058,  0.2509],\n",
       "       [ 0.2374, -0.0467,  0.3947,  0.1535,  0.2384,  1.352 ,  0.6416,\n",
       "        -0.0781,  0.7644,  0.4392,  0.0177,  0.4359,  0.1554],\n",
       "       [ 0.0753, -0.0186,  0.3191,  0.1222,  0.1433,  0.6416,  0.6968,\n",
       "        -0.2588,  0.5765,  0.3851, -0.0408,  0.2525,  0.0748],\n",
       "       [ 0.0231,  0.2194,  0.4553,  0.273 , -0.5166, -0.0781, -0.2588,\n",
       "         2.1795, -0.2801, -0.0363,  0.1208, -0.332 , -0.1485],\n",
       "       [ 0.1102,  0.0187, -0.0353, -0.0824,  0.2566,  0.7644,  0.5765,\n",
       "        -0.2801,  2.1792,  0.6795, -0.1815,  0.2323,  0.1568],\n",
       "       [ 0.4261, -0.3939,  0.06  , -0.068 ,  0.1445,  0.4392,  0.3851,\n",
       "        -0.0363,  0.6795,  1.6141, -0.3417, -0.1241,  0.2666],\n",
       "       [ 0.1411, -0.4167,  0.167 ,  0.0336,  0.1777,  0.0177, -0.0408,\n",
       "         0.1208, -0.1815, -0.3417,  1.3119,  0.0917,  0.2232],\n",
       "       [-0.0155,  0.0787,  0.1987,  0.2548, -0.0058,  0.4359,  0.2525,\n",
       "        -0.332 ,  0.2323, -0.1241,  0.0917,  0.8714, -0.1167],\n",
       "       [ 0.1224, -0.2492, -0.0081, -0.1201,  0.2509,  0.1554,  0.0748,\n",
       "        -0.1485,  0.1568,  0.2666,  0.2232, -0.1167,  0.7862]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算类内散度矩阵\n",
    "k = 13\n",
    "sw = np.zeros((k,k))\n",
    "for label, mv in zip(range(1,4),mean_vecs):\n",
    "    si = np.zeros((k,k))\n",
    "    si = np.cov(x_train_std[y_train==label].T)\n",
    "    sw+=si\n",
    "sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多类LDA,类间散度矩阵:\n",
    "\n",
    "$S_b = \\sum\\limits_{j=1}^{k}N_j(\\mu_j-\\mu)(\\mu_j-\\mu)^T$\n",
    "\n",
    "优化目标函数：\n",
    "\n",
    "$\\underbrace{arg\\;max}_W\\;\\;J(W) = \\frac{\\prod\\limits_{diag}W^TS_bW}{\\prod\\limits_{diag}W^TS_wW}$\n",
    "\n",
    "其中$\\prod\\limits_{diag}$为A的主对角线元素的乘积，$W$为$n×d$的矩阵。\n",
    "\n",
    "J(W)优化过程可以转化为：$J(W) = \\frac{\\prod\\limits_{i=1}^dw_i^TS_bw_i}{\\prod\\limits_{i=1}^dw_i^TS_ww_i} = \\prod\\limits_{i=1}^d\\frac{w_i^TS_bw_i}{w_i^TS_ww_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算类间散度矩阵\n",
    "mean_all = np.mean(x_train_std,axis =0)\n",
    "sb = np.zeros((k,k))\n",
    "for i,col_mv in enumerate(mean_vecs):\n",
    "    n = x_train[y_train == i+1,:].shape[0]\n",
    "    col_mv = col_mv.reshape(k,1)\n",
    "    mean_all = mean_all.reshape(k,1)\n",
    "    sb+=n*(col_mv- mean_all).dot((col_mv-mean_all).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(349.61780890599397,\n",
       "  array([-0.1481+0.j,  0.0908+0.j, -0.0168+0.j,  0.1484+0.j, -0.0163+0.j,\n",
       "          0.1913+0.j, -0.7338+0.j, -0.075 +0.j,  0.0018+0.j,  0.294 +0.j,\n",
       "         -0.0328+0.j, -0.3547+0.j, -0.3915+0.j])),\n",
       " (172.7615221897938,\n",
       "  array([-0.4092+0.j, -0.1577+0.j, -0.3537+0.j,  0.3223+0.j, -0.0817+0.j,\n",
       "          0.0842+0.j,  0.2823+0.j, -0.0102+0.j,  0.0907+0.j, -0.2152+0.j,\n",
       "          0.2747+0.j, -0.0124+0.j, -0.5958+0.j])),\n",
       " (3.08428579371944e-14,\n",
       "  array([ 0.1122+0.j, -0.4077+0.j,  0.0415+0.j,  0.2495+0.j, -0.0261+0.j,\n",
       "          0.1469+0.j,  0.5775+0.j, -0.0377+0.j, -0.0458+0.j,  0.0895+0.j,\n",
       "         -0.1417+0.j, -0.5463+0.j, -0.2674+0.j])),\n",
       " (2.842170943040401e-14,\n",
       "  array([ 0.7517+0.j, -0.0834+0.j, -0.2406+0.j,  0.2515+0.j, -0.0586+0.j,\n",
       "          0.1027+0.j,  0.0109+0.j, -0.025 +0.j,  0.0611+0.j, -0.0726+0.j,\n",
       "          0.1757+0.j, -0.0943+0.j, -0.4933+0.j])),\n",
       " (2.38683065228439e-14,\n",
       "  array([-0.5625+0.j    ,  0.3441+0.1058j,  0.2097+0.0049j, -0.2455-0.119j ,\n",
       "         -0.0212-0.0136j, -0.2677-0.0629j,  0.254 -0.1389j,  0.0203+0.0633j,\n",
       "         -0.0975+0.0678j, -0.0625-0.0343j, -0.1046+0.2536j,  0.0451-0.0468j,\n",
       "          0.4143+0.0271j])),\n",
       " (2.38683065228439e-14,\n",
       "  array([-0.5625-0.j    ,  0.3441-0.1058j,  0.2097-0.0049j, -0.2455+0.119j ,\n",
       "         -0.0212+0.0136j, -0.2677+0.0629j,  0.254 +0.1389j,  0.0203-0.0633j,\n",
       "         -0.0975-0.0678j, -0.0625+0.0343j, -0.1046-0.2536j,  0.0451+0.0468j,\n",
       "          0.4143-0.0271j])),\n",
       " (2.011914017736349e-14,\n",
       "  array([ 0.7064+0.j    , -0.1051+0.0269j, -0.1296-0.1105j,  0.152 -0.0196j,\n",
       "         -0.0323+0.0303j,  0.1467+0.03j  , -0.0721+0.1708j, -0.0279+0.0167j,\n",
       "          0.1133-0.0034j, -0.1218+0.1472j,  0.1299-0.0821j, -0.1054+0.0454j,\n",
       "         -0.5183-0.1488j])),\n",
       " (2.011914017736349e-14,\n",
       "  array([ 0.7064-0.j    , -0.1051-0.0269j, -0.1296+0.1105j,  0.152 +0.0196j,\n",
       "         -0.0323-0.0303j,  0.1467-0.03j  , -0.0721-0.1708j, -0.0279-0.0167j,\n",
       "          0.1133+0.0034j, -0.1218-0.1472j,  0.1299+0.0821j, -0.1054-0.0454j,\n",
       "         -0.5183+0.1488j])),\n",
       " (1.6526817988232273e-14,\n",
       "  array([ 0.2618+0.j, -0.4418+0.j,  0.4509+0.j,  0.1395+0.j,  0.055 +0.j,\n",
       "         -0.1571+0.j,  0.3502+0.j, -0.0114+0.j,  0.0283+0.j,  0.2005+0.j,\n",
       "         -0.061 +0.j, -0.0196+0.j, -0.5638+0.j])),\n",
       " (7.851147685003662e-15,\n",
       "  array([ 0.6487+0.j    , -0.1407-0.1028j, -0.3928-0.1345j, -0.0009+0.0379j,\n",
       "          0.0365+0.0429j,  0.0084+0.0028j, -0.1388-0.0669j, -0.1257+0.1329j,\n",
       "          0.0996+0.0105j, -0.2751-0.0884j,  0.1455-0.0416j, -0.2894-0.0087j,\n",
       "         -0.2979+0.1597j])),\n",
       " (7.851147685003662e-15,\n",
       "  array([ 0.6487-0.j    , -0.1407+0.1028j, -0.3928+0.1345j, -0.0009-0.0379j,\n",
       "          0.0365-0.0429j,  0.0084-0.0028j, -0.1388+0.0669j, -0.1257-0.1329j,\n",
       "          0.0996-0.0105j, -0.2751+0.0884j,  0.1455+0.0416j, -0.2894+0.0087j,\n",
       "         -0.2979-0.1597j])),\n",
       " (5.362754693188859e-15,\n",
       "  array([-0.6957+0.j,  0.2004+0.j,  0.0612+0.j,  0.1418+0.j,  0.1156+0.j,\n",
       "         -0.0082+0.j,  0.1035+0.j,  0.135 +0.j,  0.0097+0.j,  0.1349+0.j,\n",
       "         -0.2097+0.j,  0.1732+0.j,  0.5634+0.j])),\n",
       " (4.94593897841094e-15,\n",
       "  array([-0.4509+0.j,  0.2732+0.j, -0.114 +0.j, -0.1572+0.j, -0.3716+0.j,\n",
       "         -0.1071+0.j, -0.0222+0.j,  0.0981+0.j,  0.0681+0.j, -0.1168+0.j,\n",
       "         -0.1136+0.j, -0.0082+0.j,  0.7024+0.j]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 广义特征值\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(sw).dot(sb))\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]),eigen_vecs[:,i]) for i in range(len(eigen_vals))]\n",
    "eigen_pairs = sorted(eigen_pairs,key=lambda k: k[0],reverse=True)\n",
    "eigen_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6692795600710418, 0.33072043992895805, 5.4408181446965336e-17, 3.103792820716207e-17, 3.103792820716207e-17, 1.2662094610372913e-17, 1.2662094610372913e-17, 1.0266016233719437e-17, -9.468098532987346e-18, -2.315922774551034e-17, -2.315922774551034e-17, -3.163758021123117e-17, -5.904302888955381e-17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32447 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24615 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21028 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21035 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 36776 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35782 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21147 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 27604 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 21152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 29420 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 31435 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32447 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24615 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21028 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21035 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 36776 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35782 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21147 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 27604 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32047 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 21152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 29420 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/yel/.local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 31435 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 线性判别捕捉\n",
    "# 从捕捉到的特征值发现，前两个可以占据大部分数据集特征了，接下来可视化表示更加直观地观察\n",
    "# 线性判别捕捉，计算辨识力\n",
    "tot = sum(eigen_vals.real)\n",
    "discr = []\n",
    "for i in sorted(eigen_vals.real, reverse=True):\n",
    "    discr.append(i / tot)\n",
    "print(discr)\n",
    "cum_discr = np.cumsum(discr) # 计算累加方差\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 显示中文\n",
    "plt.bar(range(1,14),discr,alpha=0.5,align='center',label='独立辨识力')\n",
    "plt.step(range(1,14),cum_discr,where='mid',label='累加辨识力')\n",
    "plt.ylabel('\"辨识力\"比')\n",
    "plt.xlabel('线性判别')\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1481 -0.4092]\n",
      " [ 0.0908 -0.1577]\n",
      " [-0.0168 -0.3537]\n",
      " [ 0.1484  0.3223]\n",
      " [-0.0163 -0.0817]\n",
      " [ 0.1913  0.0842]\n",
      " [-0.7338  0.2823]\n",
      " [-0.075  -0.0102]\n",
      " [ 0.0018  0.0907]\n",
      " [ 0.294  -0.2152]\n",
      " [-0.0328  0.2747]\n",
      " [-0.3547 -0.0124]\n",
      " [-0.3915 -0.5958]]\n"
     ]
    }
   ],
   "source": [
    "# 数据投影降维\n",
    "# 变换矩阵\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis].real, eigen_pairs[1][1][:, np.newaxis].real))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 样本数据投影到低维空间\n",
    "x_train_lda = x_train_std.dot(w)\n",
    "colors = ['r', 'g', 'b']\n",
    "marks = ['s', 'x', 'o']\n",
    "for l, c, m in zip(np.unique(y_train), colors, marks):\n",
    "    plt.scatter(x_train_lda[y_train == l, 0],\n",
    "x_train_lda[y_train == l, 1] * -1,\n",
    "c=c, label=l, marker=m)\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('LD 2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}